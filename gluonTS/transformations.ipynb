{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code pour tester les transformations. \n",
    "But : être au clair sur les transformations de la librarie. Les SimpleTransformation et les FlatMapTransformation. Ensuite les datsets etc. Et tester tous les types de transformations actuellement existants. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.transform import (\n",
    "    AddObservedValuesIndicator,\n",
    "    ExpectedNumInstanceSampler,\n",
    "    InstanceSampler,\n",
    "    InstanceSplitter,\n",
    "    SelectFields,\n",
    "    TestSplitSampler,\n",
    "    Transformation,\n",
    "    ValidationSplitSampler,\n",
    ")\n",
    "from gluonts.transform import (\n",
    "    Transformation,\n",
    "    Chain,\n",
    "    RemoveFields,\n",
    "    SetField,\n",
    "    AsNumpyArray,\n",
    "    AddObservedValuesIndicator,\n",
    "    AddTimeFeatures,\n",
    "    AddAgeFeature,\n",
    "    VstackFeatures,\n",
    "    InstanceSplitter,\n",
    "    ValidationSplitSampler,\n",
    "    TestSplitSampler,\n",
    "    ExpectedNumInstanceSampler,\n",
    "    MissingValueImputation,\n",
    "    DummyValueImputation,\n",
    ")\n",
    "from gluonts.dataset.field_names import FieldName\n",
    "from gluonts.dataset.repository import get_dataset\n",
    "from gluonts.time_feature import (\n",
    "    TimeFeature,\n",
    "    time_features_from_frequency_str,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB. La classe abstraite redéfinit les additions. Donc on peut additionner des Transformations simplement. Elles sont appliquées de manière séquentielle. Et on renvoie un objet ensuite itérable de type Dic[Any]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_feature = time_features_from_frequency_str(\"H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transformation(num_feat_static_real,\n",
    "                          num_feat_dynamic_real,\n",
    "                          num_feat_static_cat,\n",
    "                          imputation_method,\n",
    "                          distr_output,\n",
    "                          time_features,\n",
    "                          prediction_length) -> Transformation:\n",
    "        \n",
    "        remove_field_names = []\n",
    "        if num_feat_static_real == 0:\n",
    "            remove_field_names.append(FieldName.FEAT_STATIC_REAL)\n",
    "        if num_feat_dynamic_real == 0:\n",
    "            remove_field_names.append(FieldName.FEAT_DYNAMIC_REAL)\n",
    "     \n",
    "        return Chain(\n",
    "            [RemoveFields(field_names=remove_field_names)]\n",
    "            + (\n",
    "                [SetField(output_field=FieldName.FEAT_STATIC_CAT, value=[0])]\n",
    "                if not num_feat_static_cat > 0\n",
    "                else []\n",
    "            )\n",
    "            + (\n",
    "                [\n",
    "                    SetField(\n",
    "                        output_field=FieldName.FEAT_STATIC_REAL, value=[0.0] #setField : set un field dans un dico avec une valeur donnée. \n",
    "                    )\n",
    "                ]\n",
    "                if not num_feat_static_real > 0\n",
    "                else []\n",
    "            )\n",
    "            + [\n",
    "                AsNumpyArray(\n",
    "                    field=FieldName.FEAT_STATIC_CAT,\n",
    "                    expected_ndim=1,\n",
    "                    dtype=int,\n",
    "                ),\n",
    "                AsNumpyArray(\n",
    "                    field=FieldName.FEAT_STATIC_REAL,\n",
    "                    expected_ndim=1,\n",
    "                ),\n",
    "                AsNumpyArray(\n",
    "                    field=FieldName.TARGET,\n",
    "                    # in the following line, we add 1 for the time dimension\n",
    "                    expected_ndim=1 + len(distr_output.event_shape),\n",
    "                ),\n",
    "                AddObservedValuesIndicator(\n",
    "                    target_field=FieldName.TARGET,\n",
    "                    output_field=FieldName.OBSERVED_VALUES,\n",
    "                    imputation_method=imputation_method,\n",
    "                ),\n",
    "                AddTimeFeatures(\n",
    "                    start_field=FieldName.START,\n",
    "                    target_field=FieldName.TARGET,\n",
    "                    output_field=FieldName.FEAT_TIME,\n",
    "                    time_features=time_features,\n",
    "                    pred_length=prediction_length,\n",
    "                ),\n",
    "                AddAgeFeature(\n",
    "                    target_field=FieldName.TARGET,\n",
    "                    output_field=FieldName.FEAT_AGE, #on donne des noms aux outputs fields. Puis on a aussi des noms aux inputs fields.\n",
    "                    pred_length=prediction_length,\n",
    "                    log_scale=True,\n",
    "                ),\n",
    "                VstackFeatures(\n",
    "                    output_field=FieldName.FEAT_TIME,\n",
    "                    input_fields=[FieldName.FEAT_TIME, FieldName.FEAT_AGE]\n",
    "                    + (\n",
    "                        [FieldName.FEAT_DYNAMIC_REAL]\n",
    "                        if num_feat_dynamic_real > 0\n",
    "                        else []\n",
    "                    ),\n",
    "                ),\n",
    "                AsNumpyArray(FieldName.FEAT_TIME, expected_ndim=2),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "def super_simple_transformation()->Transformation:\n",
    "     return Chain([ AsNumpyArray(\n",
    "                    field=FieldName.TARGET,\n",
    "                    # in the following line, we add 1 for the time dimension\n",
    "                    expected_ndim=1,\n",
    "                ),\n",
    "                AddObservedValuesIndicator(\n",
    "                    target_field=FieldName.TARGET,\n",
    "                    output_field=FieldName.OBSERVED_VALUES\n",
    "                ),\n",
    "                  AddAgeFeature(\n",
    "                    target_field=FieldName.TARGET,\n",
    "                    output_field=FieldName.FEAT_AGE, #on donne des noms aux outputs fields. Puis on a aussi des noms aux inputs fields.\n",
    "                    pred_length=12,\n",
    "                    log_scale=True,\n",
    "                ),\n",
    "                AddTimeFeatures(\n",
    "                    start_field=FieldName.START,\n",
    "                    target_field=FieldName.TARGET,\n",
    "                    output_field=FieldName.FEAT_TIME,\n",
    "                    pred_length=12,\n",
    "                    time_features=time_feature\n",
    "                ),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(\"electricity\")  #va contenir un .train, un .test directement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': array([14., 18., 21., ...,  6.,  9.,  7.], dtype=float32),\n",
       " 'start': Period('2012-01-01 00:00', 'H'),\n",
       " 'feat_static_cat': array([0], dtype=int32),\n",
       " 'item_id': 0}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset.train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformation = super_simple_transformation()\n",
    "transformed_training_data = Transformation.apply(\n",
    "                dataset.train, is_train=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': array([14., 18., 21., ...,  6.,  9.,  7.], dtype=float32),\n",
       " 'start': Period('2012-01-01 00:00', 'H'),\n",
       " 'feat_static_cat': array([0], dtype=int32),\n",
       " 'item_id': 0,\n",
       " 'observed_values': array([1., 1., 1., ..., 1., 1., 1.], dtype=float32),\n",
       " 'feat_dynamic_age': array([[0.30103   , 0.47712126, 0.60206   , ..., 4.3231077 , 4.323128  ,\n",
       "         4.3231487 ]], dtype=float32),\n",
       " 'time_feat': array([[-0.5       , -0.45652175, -0.41304347, ...,  0.23913044,\n",
       "          0.2826087 ,  0.32608697],\n",
       "        [ 0.5       ,  0.5       ,  0.5       , ..., -0.5       ,\n",
       "         -0.5       , -0.5       ],\n",
       "        [-0.5       , -0.5       , -0.5       , ...,  0.33333334,\n",
       "          0.33333334,  0.33333334],\n",
       "        [-0.5       , -0.5       , -0.5       , ..., -0.10273973,\n",
       "         -0.10273973, -0.10273973]], dtype=float32)}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(transformed_training_data))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
